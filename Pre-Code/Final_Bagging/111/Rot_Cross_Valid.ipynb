{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 2048)\n",
      "(2000, 2048)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/ubuntu/caffe/python\")\n",
    "import caffe\n",
    "import leveldb\n",
    "import numpy as np\n",
    "from caffe.proto import caffe_pb2\n",
    "\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from numpy import genfromtxt\n",
    "\n",
    "#add cross validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "input_x = np.load(\"train_res152.npz\")[\"arr_0\"]\n",
    "test_x = np.load(\"test_res152_hidden.npz\")[\"arr_0\"]\n",
    "input_label = genfromtxt('/home/ubuntu/caffe/examples/images/Files/train.csv', delimiter=',')\n",
    "input_label = input_label[1:7001,1].reshape(-1)\n",
    "\n",
    "print (input_x.shape)\n",
    "print (test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictin the labels\n",
      "Writing Done!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "#for max_iter in [100,500,1000,3000]:\n",
    "#for C_pram in [0.0005,0.002,0.005,0.007,0.1,0.5,1]: #best 0.001,0.01 #best of best 0.001\n",
    "#for s in ['lbfgs']: #newton-cg tested [0.80840456  0.82571429  0.81357143  0.8084346   0.80601288] #sag too slow\n",
    "            #for multi_class in ['ovr','multinomial']:\n",
    "#for C_pram in [0.001]:\n",
    "clf = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=0.001, fit_intercept=True,\n",
    "                       intercept_scaling=1, class_weight=None, random_state=None, \n",
    "                       solver='lbfgs', max_iter=3000, multi_class='multinomial',\n",
    "                       verbose=0, warm_start=False, n_jobs=-1)\n",
    "\n",
    "# clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "#                                  max_depth=1, random_state=0)\n",
    "#clf = AdaBoostClassifier(n_estimators=100)\n",
    "# scores = cross_val_score(clf, input_x, input_label, cv=5)\n",
    "# print(scores)\n",
    "# print(scores.mean)\n",
    "\n",
    "#tol 0.00001 [ 0.81980057  0.82357143  0.81285714  0.81272337  0.80100215]\n",
    "\n",
    "clf.fit(input_x, input_label)\n",
    "print (\"Predictin the labels\")\n",
    "y_pred = clf.predict(test_x)\n",
    "filename = \"predict_res152_hidden.csv\"\n",
    "f = open(filename, \"w\")\n",
    "f.write('Id,Prediction\\n')\n",
    "\n",
    "if ((len(y_pred))<1000):\n",
    "   zeros = np.zeros(2000)\n",
    "   y_pred = np.append(y_pred, zeros).reshape(-1)\n",
    "\n",
    "for i in range(0,len(y_pred)):\n",
    "   d = '{0},{1}\\n'.format(i+1,int(y_pred[i]))\n",
    "   f.write(d)\n",
    "print (\"Writing Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split the train data & test data\n"
     ]
    }
   ],
   "source": [
    "#Corss Validation\n",
    "# clf = SVC(C=100.0,decision_function_shape='ovr',max_iter=900,probability=False)\n",
    "# scores = cross_val_score(clf, input_x, input_label, cv=5)\n",
    "# print (scores)\n",
    "# clf = SVC(C=100.0,decision_function_shape='ovr',max_iter=800,probability=False)\n",
    "# scores = cross_val_score(clf, input_x, input_label, cv=5)\n",
    "# print (scores)\n",
    "# clf = SVC(C=100.0,decision_function_shape='ovr',max_iter=700,probability=False)\n",
    "# scores = cross_val_score(clf, input_x, input_label, cv=5)\n",
    "# print (scores)\n",
    "# clf = SVC(C=100.0,decision_function_shape='ovr',max_iter=600,probability=False)\n",
    "# scores = cross_val_score(clf, input_x, input_label, cv=5)\n",
    "# print (scores)\n",
    "# clf = SVC(C=100.0,decision_function_shape='ovr',max_iter=400,probability=False)\n",
    "# scores = cross_val_score(clf, input_x, input_label, cv=5)\n",
    "# print (scores)\n",
    "\n",
    "import random\n",
    "#set random seed\n",
    "random.seed(42)\n",
    "#set cross valid test size\n",
    "test_size = 0.25\n",
    "#get a test size list\n",
    "sample  = random.sample(range(len(input_x)/4),int(len(input_x)/4*test_size))\n",
    "test_sample = np.asarray(sample)\n",
    "#get the other part of index as train\n",
    "mask = np.ones(len(input_x)/4, dtype=bool)\n",
    "mask[sample] = False\n",
    "universal = np.arange(len(input_x)/4)\n",
    "train_sample = universal[mask]\n",
    "\n",
    "#Extent to whole test_set & test_label\n",
    "#test_sample_u is the index matrix of test data\n",
    "test_sample_u = np.append(test_sample,test_sample+len(input_x)/4) #90 degree\n",
    "test_sample_u = np.append(test_sample_u,test_sample+2*len(input_x)/4) #180 degree\n",
    "test_sample_u = np.append(test_sample_u,test_sample+3*len(input_x)/4) #270 degree\n",
    "\n",
    "#Extent to whole train_set & train_label\n",
    "#train_sample_u is the index matrix of test data\n",
    "train_sample_u = np.append(train_sample,train_sample+len(input_x)/4)\n",
    "train_sample_u = np.append(train_sample_u,train_sample+2*len(input_x)/4) #180 degree\n",
    "train_sample_u = np.append(train_sample_u,train_sample+3*len(input_x)/4) #270 degree\n",
    "\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(input_x, input_label, test_size=0.1, random_state=42)\n",
    "X_train = input_x[train_sample_u]\n",
    "X_test = input_x[test_sample_u]\n",
    "y_train = input_label[train_sample_u]\n",
    "y_test = input_label[test_sample_u]\n",
    "\n",
    "print(\"Split the train data & test data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('training accuracy is', 1.0)\n",
      "('validation accuracy is', 0.76671428571428568)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=1500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('training accuracy is', 1.0)\n",
      "('validation accuracy is', 0.7658571428571429)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('training accuracy is', 0.99971428571428567)\n",
      "('validation accuracy is', 0.76371428571428568)\n",
      "('training accuracy is', 0.97799999999999998)\n",
      "('validation accuracy is', 0.75328571428571434)\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(C=100.0,decision_function_shape='ovr',max_iter=2000,probability=False)\n",
    "clf.fit(X_train, y_train)\n",
    "print('training accuracy is', clf.score(X_train,y_train))\n",
    "print('validation accuracy is', clf.score(X_test,y_test))\n",
    "clf = SVC(C=100.0,decision_function_shape='ovr',max_iter=1500,probability=False)\n",
    "clf.fit(X_train, y_train)\n",
    "print('training accuracy is', clf.score(X_train,y_train))\n",
    "print('validation accuracy is', clf.score(X_test,y_test))\n",
    "clf = SVC(C=100.0,decision_function_shape='ovr',max_iter=1000,probability=False)\n",
    "clf.fit(X_train, y_train)\n",
    "print('training accuracy is', clf.score(X_train,y_train))\n",
    "print('validation accuracy is', clf.score(X_test,y_test))\n",
    "clf = SVC(C=100.0,decision_function_shape='ovr',max_iter=600,probability=False)\n",
    "clf.fit(X_train, y_train)\n",
    "print('training accuracy is', clf.score(X_train,y_train))\n",
    "print('validation accuracy is', clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('training accuracy is', 1.0)\n",
      "('validation accuracy is', 0.76600000000000001)\n",
      "('training accuracy is', 1.0)\n",
      "('validation accuracy is', 0.76600000000000001)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('training accuracy is', 1.0)\n",
      "('validation accuracy is', 0.76700000000000002)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py:220: ConvergenceWarning: Solver terminated early (max_iter=4000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('training accuracy is', 1.0)\n",
      "('validation accuracy is', 0.76600000000000001)\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(C=100.0,decision_function_shape='ovr',max_iter=-1,probability=False)\n",
    "clf.fit(X_train, y_train)\n",
    "print('training accuracy is', clf.score(X_train,y_train))\n",
    "print('validation accuracy is', clf.score(X_test,y_test))\n",
    "clf = SVC(C=800.0,decision_function_shape='ovr',max_iter=-1,probability=False)\n",
    "clf.fit(X_train, y_train)\n",
    "print('training accuracy is', clf.score(X_train,y_train))\n",
    "print('validation accuracy is', clf.score(X_test,y_test))\n",
    "clf = SVC(C=100.0,decision_function_shape='ovr',max_iter=3000,probability=False)\n",
    "clf.fit(X_train, y_train)\n",
    "print('training accuracy is', clf.score(X_train,y_train))\n",
    "print('validation accuracy is', clf.score(X_test,y_test))\n",
    "clf = SVC(C=100.0,decision_function_shape='ovr',max_iter=4000,probability=False)\n",
    "clf.fit(X_train, y_train)\n",
    "print('training accuracy is', clf.score(X_train,y_train))\n",
    "print('validation accuracy is', clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(C=1.0,decision_function_shape='ovr',max_iter=-1,probability=False)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('training accuracy is', clf.score(X_train,y_train))\n",
    "print('validation accuracy is', clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = SVC(C=100.0,decision_function_shape='ovr',max_iter=3500,probability=False)\n",
    "clf.fit(X_train, y_train)\n",
    "print('training accuracy is', clf.score(X_train,y_train))\n",
    "print('validation accuracy is', clf.score(X_test,y_test))\n",
    "clf = SVC(C=100.0,decision_function_shape='ovr',max_iter=5000,probability=False)\n",
    "clf.fit(X_train, y_train)\n",
    "print('training accuracy is', clf.score(X_train,y_train))\n",
    "print('validation accuracy is', clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = SVC(C=100.0,decision_function_shape='ovr',max_iter=6000,probability=False)\n",
    "clf.fit(X_train, y_train)\n",
    "print('training accuracy is', clf.score(X_train,y_train))\n",
    "print('validation accuracy is', clf.score(X_test,y_test))\n",
    "clf = SVC(C=100.0,decision_function_shape='ovr',max_iter=7000,probability=False)\n",
    "clf.fit(X_train, y_train)\n",
    "print('training accuracy is', clf.score(X_train,y_train))\n",
    "print('validation accuracy is', clf.score(X_test,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
